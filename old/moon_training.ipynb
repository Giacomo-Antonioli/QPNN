{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96c3b18d-774d-4455-b8fc-078b7258ee0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mgiacomoantonioli\u001B[0m (\u001B[33mquantum_kets\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\giaco\\Documents\\QNN\\wandb\\run-20240624_115522-zfsnu967</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/quantum_kets/QPNN_Torch/runs/zfsnu967' target=\"_blank\">dashing-flower-293</a></strong> to <a href='https://wandb.ai/quantum_kets/QPNN_Torch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/quantum_kets/QPNN_Torch' target=\"_blank\">https://wandb.ai/quantum_kets/QPNN_Torch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/quantum_kets/QPNN_Torch/runs/zfsnu967' target=\"_blank\">https://wandb.ai/quantum_kets/QPNN_Torch/runs/zfsnu967</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 1: 0.4965\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 2: 0.4689\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 3: 0.4223\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 4: 0.4042\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 5: 0.4015\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 6: 0.4012\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 7: 0.4012\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 8: 0.4012\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 9: 0.4012\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 10: 0.4012\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giaco\\AppData\\Local\\Temp\\ipykernel_37648\\780237290.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, requires_grad=False).float()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:zfsnu967) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>█▆▃▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>85.0</td></tr><tr><td>loss</td><td>0.40123</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dashing-flower-293</strong> at: <a href='https://wandb.ai/quantum_kets/QPNN_Torch/runs/zfsnu967' target=\"_blank\">https://wandb.ai/quantum_kets/QPNN_Torch/runs/zfsnu967</a><br/> View project at: <a href='https://wandb.ai/quantum_kets/QPNN_Torch' target=\"_blank\">https://wandb.ai/quantum_kets/QPNN_Torch</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240624_115522-zfsnu967\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:zfsnu967). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\giaco\\Documents\\QNN\\wandb\\run-20240624_115609-e8cbw1uq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/quantum_kets/QPNN_Torch/runs/e8cbw1uq' target=\"_blank\">lemon-darkness-294</a></strong> to <a href='https://wandb.ai/quantum_kets/QPNN_Torch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/quantum_kets/QPNN_Torch' target=\"_blank\">https://wandb.ai/quantum_kets/QPNN_Torch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/quantum_kets/QPNN_Torch/runs/e8cbw1uq' target=\"_blank\">https://wandb.ai/quantum_kets/QPNN_Torch/runs/e8cbw1uq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 1: 0.4019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread IntMsgThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\threading.py\", line 982, in run\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 178\u001B[0m\n\u001B[0;32m    176\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAverage loss over epoch \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{:.4f}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(epoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, avg_loss))\n\u001B[0;32m    177\u001B[0m     wandb\u001B[38;5;241m.\u001B[39mlog({ \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m: avg_loss})\n\u001B[1;32m--> 178\u001B[0m     \u001B[38;5;28minput\u001B[39m()\n\u001B[0;32m    180\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model(X)\n\u001B[0;32m    181\u001B[0m predictions \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(y_pred, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1260\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[1;32m-> 1262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_request(\n\u001B[0;32m   1263\u001B[0m     \u001B[38;5;28mstr\u001B[39m(prompt),\n\u001B[0;32m   1264\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent_ident[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshell\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   1265\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_parent(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshell\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1266\u001B[0m     password\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1267\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1302\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1303\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m   1304\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1306\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1307\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 322, in check_internal_messages\n",
      "    self._loop_check_status(\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 233, in _loop_check_status\n",
      "    local_handle = request()\n",
      "                   ^^^^^^^^^\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 892, in deliver_internal_messages\n",
      "    return self._deliver_internal_messages(internal_message)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 510, in _deliver_internal_messages\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: While tearing down the service manager. The following error has occurred: [WinError 10054] Connessione in corso interrotta forzatamente dall'host remoto\n",
      "    return self._deliver_record(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 453, in _deliver_record\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py\", line 455, in _deliver_record\n",
      "    interface._publish(record)\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"C:\\Users\\giaco\\anaconda3\\envs\\qiskit46\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Connessione in corso interrotta forzatamente dall'host remoto\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane.operation import Operation, AnyWires\n",
    "\n",
    "#dev0 = qml.device(\"default.qubit\",wires=3)\n",
    "print(torch.cuda.is_available())\n",
    "class RBSGate(Operation):\n",
    "    num_wires = 2  \n",
    "\n",
    "    def __init__(self, theta, wires, id=None):\n",
    "        all_wires = qml.wires.Wires(wires)\n",
    "        super().__init__(theta, wires=all_wires, id=id)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_decomposition(theta, wires):\n",
    "        decomp = [\n",
    "                qml.Hadamard(wires=wires[0]),\n",
    "                qml.Hadamard(wires=wires[1]),\n",
    "                qml.CZ(wires=wires),\n",
    "                qml.RY(theta/2.,wires=wires[0]),\n",
    "                qml.RY(-theta/2.,wires=wires[1]),\n",
    "                qml.CZ(wires=wires),\n",
    "                qml.Hadamard(wires=wires[0]),\n",
    "                qml.Hadamard(wires=wires[1])\n",
    "            ]\n",
    "        return decomp\n",
    "n_qubits = 3\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def probs_single(inputs, weights):\n",
    "    shape=[3,1]\n",
    "    \n",
    "    qml.PauliX(wires=0)\n",
    "    # make the input vector norm1\n",
    "    \n",
    "    # load input\n",
    "    prd_fact=1.0\n",
    "    for qi in range(0,shape[0]-1):\n",
    "        theta_i=torch.arccos((inputs[...,qi])/prd_fact)#removed np.sqrt\n",
    "        prd_fact=prd_fact*torch.sin(theta_i)\n",
    "#        print(f\"qubit: {qi}, input: {inputs[...,qi]}, fact_new: {prd_fact}, theta_i: {theta_i}\")\n",
    "#        input()\n",
    "        RBSGate(theta_i,wires=[qi,qi+1],id=f\"$\\\\alpha_{qi}$\")\n",
    "    \n",
    "    # parametric circuit\n",
    "    ctr=0\n",
    "    for j in range(shape[1]):\n",
    "        for i in range(0,shape[0]-j-1):\n",
    "            RBSGate(weights[0][ctr],[i,i+1],id=f\"$\\\\theta_{ctr}$\")\n",
    "            ctr+=1    \n",
    "    return qml.probs(wires=range(shape[0]-shape[1],shape[0]))\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "# Set random seeds\n",
    "#torch.manual_seed(42)\n",
    "#np.random.seed(42)\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.1)\n",
    "\n",
    "X_mean, X_std=np.mean(X,axis=0), np.std(X,axis=0,ddof=1)\n",
    "\n",
    "X=(X-X_mean)/X_std\n",
    "\n",
    "X=np.hstack((X,np.ones(X.shape[0])[:,None]))\n",
    "X=np.array([np.clip(row/np.sqrt(np.sum(row**2)),-1,1) for row in X])\n",
    "def stereo_pj(X):\n",
    "    n,m=np.shape(X)\n",
    "    newX=np.zeros((n,m+1))\n",
    "    for rowindex,x in enumerate(X):\n",
    "        s=np.sum(pow(x,2))\n",
    "        for index in range(m):\n",
    "            newX[rowindex,index]=2*x[index]/(s+1)\n",
    "        newX[rowindex,m]=(s-1)/(s+1)\n",
    "    return newX\n",
    "\n",
    "#X=stereo_pj(X)\n",
    "y_ = torch.unsqueeze(torch.tensor(y,requires_grad=False), 1)  # used for one-hot encoded labels\n",
    "y_hot = torch.scatter(torch.zeros((200, 2),requires_grad=False), 1, y_, 1)\n",
    "\n",
    "c = [\"#1f77b4\" if y_ == 0 else \"#ff7f0e\" for y_ in y]  # colours for each class\n",
    "#plt.axis(\"off\")\n",
    "#plt.scatter(X[:, 0], X[:, 1], c=c)\n",
    "#plt.show()\n",
    "\n",
    "n_layers = 1\n",
    "n_pars = 2\n",
    "weight_shapes = {\"weights\": (n_layers, n_pars)}\n",
    "qlayer = qml.qnn.TorchLayer(probs_single, weight_shapes)\n",
    "clayer_1 = torch.nn.Linear(3, 3)\n",
    "\n",
    "softmax_pre = torch.nn.Softmax(dim=1)\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "optimizers=[\"SGD\",\"ADAM\",\"ADAMW\",\"RMSPROP\"]\n",
    "epochs_list = [10, 50, 100]\n",
    "lr_list=[0.1,0.2,0.01,0.001,0.5,0.9]\n",
    "layers = [qlayer, softmax]\n",
    "\n",
    "for optindex in optimizers:\n",
    "    for epochs in epochs_list:\n",
    "        for lr in lr_list:\n",
    "                        \n",
    "            model = torch.nn.Sequential(*layers)\n",
    "            #print(model)\n",
    "            \n",
    "            #print([pm for pm in model.parameters()])\n",
    "            match optindex:\n",
    "                case \"SGD\":\n",
    "                     opt = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "                case \"ADAM\":\n",
    "                     opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "                case \"ADAMW\":\n",
    "                     opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "                case \"RMSPROP\":\n",
    "                     opt = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "\n",
    "            \n",
    "            loss = torch.nn.L1Loss()\n",
    "            \n",
    "            X = torch.tensor(X, requires_grad=False).float()\n",
    "            y_hot = y_hot.float()\n",
    "            \n",
    "            batch_size = 1\n",
    "            batches = 200 // batch_size\n",
    "            \n",
    "            #print(X)\n",
    "            data_loader = torch.utils.data.DataLoader(\n",
    "                list(zip(X, y_hot)), batch_size=batch_size, shuffle=False, drop_last=True\n",
    "            )\n",
    "            \n",
    "            \n",
    "            run = wandb.init(\n",
    "                # Set the project where this run will be logged\n",
    "                project=\"QPNN_Torch\",\n",
    "                entity=\"quantum_kets\",\n",
    "                # Track hyperparameters and run metadata\n",
    "                config={\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"epochs\": epochs,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"dataset\": \"moon\",\n",
    "                    \"optimizer\": optindex,\n",
    "                    \"structure\": \"q-smax\",\n",
    "                    \"achitecture\": \"extrawire\",\n",
    "                    \"normalization\": \"stdnorm\"\n",
    "                },\n",
    "            )\n",
    "            for epoch in range(epochs):\n",
    "            \n",
    "                running_loss = 0\n",
    "            \n",
    "                for xs, ys in data_loader:\n",
    "                    opt.zero_grad()\n",
    "            \n",
    "            #        print(xs)\n",
    "                    #print(model(xs))\n",
    "                    #print(ys)\n",
    "                    \n",
    "                    loss_evaluated = loss(model(xs), ys)\n",
    "                    loss_evaluated.backward()\n",
    "            \n",
    "                    opt.step()\n",
    "            \n",
    "                    running_loss += loss_evaluated\n",
    "                \n",
    "                avg_loss = running_loss / batches\n",
    "                print(\"Average loss over epoch {}: {:.4f}\".format(epoch + 1, avg_loss))\n",
    "                wandb.log({ \"loss\": avg_loss})\n",
    "                input()\n",
    "            \n",
    "            y_pred = model(X)\n",
    "            predictions = torch.argmax(y_pred, axis=1).detach().numpy()\n",
    "            \n",
    "            correct = [1 if p == p_true else 0 for p, p_true in zip(predictions, y)]\n",
    "            accuracy = sum(correct) / len(correct)\n",
    "            print(f\"Accuracy: {accuracy * 100}%\")\n",
    "            wandb.log({\"accuracy\":accuracy * 100})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eafd479-f4c7-4d79-a0f2-8a31e8941725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
